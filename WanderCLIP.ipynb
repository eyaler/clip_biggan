{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WanderCLIP.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPROGn54PfZ9n5e1UfZoCXH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/clip_biggan/blob/main/WanderCLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwTP4MYk0bYn"
      },
      "source": [
        "# BigGAN + CLIP + CMA-ES\n",
        "\n",
        "[j.mp/wanderclip](https://j.mp/wanderclip)\n",
        "\n",
        "By Eyal Gruss [@eyaler](https://twitter.com/eyaler) [eyalgruss.com](https://eyalgruss.com)\n",
        "\n",
        "Based on SIREN+CLIP Colabs by: [@advadnoun](https://twitter.com/advadnoun), [@norod78](https://twitter.com/norod78)\n",
        "\n",
        "Using the works:\n",
        "\n",
        "https://github.com/openai/CLIP\n",
        "\n",
        "https://tfhub.dev/deepmind/biggan-deep-512\n",
        "\n",
        "https://github.com/huggingface/pytorch-pretrained-BigGAN\n",
        "\n",
        "http://www.aiartonline.com/design-2019/eyal-gruss (WanderGAN)\n",
        "\n",
        "Other CLIP notebooks: https://www.reddit.com/r/MachineLearning/comments/ldc6oc/p_list_of_sitesprogramsprojects_that_use_openais\n",
        "\n",
        "A curated list of more online generative tools see: [j.mp/generativetools](https://j.mp/generativetools)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWmKTmvBg7z5",
        "cellView": "form"
      },
      "source": [
        "#@title Restart after running this cell!\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\"\n",
        "\n",
        "!pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SDpkkK7cU1y",
        "cellView": "form"
      },
      "source": [
        "#@title Setup\n",
        "!pip install pytorch-pretrained-biggan\n",
        "from pytorch_pretrained_biggan import BigGAN\n",
        "last_gen_model = 'biggan-deep-512'\n",
        "biggan_model = BigGAN.from_pretrained(last_gen_model).cuda().eval()\n",
        "\n",
        "%cd /content\n",
        "!git clone --depth 1 https://github.com/openai/CLIP\n",
        "!pip install ftfy\n",
        "%cd /content/CLIP\n",
        "import clip\n",
        "last_clip_model = 'ViT-B/32'\n",
        "perceptor, preprocess = clip.load(last_clip_model)\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "!pip install cma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOWzPLrBbdxW",
        "cellView": "form"
      },
      "source": [
        "#@title Generate!\n",
        "#@markdown 1. For **prompt** OpenAI suggest to use the template \"A photo of a X.\" or \"A photo of a X, a type of Y.\" [[paper]](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf)\n",
        "#@markdown 2. For **initial_class** you can either use free text or select a special option from the drop-down list.\n",
        "#@markdown 3. Free text and 'From prompt' might fail to find an appropriate ImageNet class.\n",
        "#@markdown 4. **seed**=0 means no seed.\n",
        "prompt = 'A photo of a rainbow unicorn.' #@param {type:'string'}\n",
        "gen_model = 'biggan-deep' #@param ['biggan-deep', 'sigmoid']\n",
        "size = '512' #@param [512, 256, 128] \n",
        "color = True #@param {type:'boolean'}\n",
        "initial_class = 'Random mix' #@param ['From prompt', 'Random class', 'Random Dirichlet', 'Random mix', 'Random embeddings'] {allow-input: true}\n",
        "optimize_class = True #@param {type:'boolean'}\n",
        "class_smoothing = 0.1 #@param {type:'number'}\n",
        "truncation = 1 #@param {type:'number'}\n",
        "stochastic_truncation = False #@param {type:'boolean'}\n",
        "optimizer = 'CMA-ES' #@param ['SGD','Adam','CMA-ES','CMA-ES + SGD interleaved','CMA-ES + Adam interleaved','CMA-ES + terminal SGD','CMA-ES + terminal Adam']\n",
        "pop_size = 50 #@param {type:'integer'}\n",
        "clip_model = 'ViT-B/32' #@param ['ViT-B/32','RN50','RN101','RN50x4']\n",
        "augmentations =  64#@param {type:'integer'}\n",
        "learning_rate =  0.1#@param {type:'number'}\n",
        "noise_normality_loss =  0#@param {type:'number'}\n",
        "embed_normality_loss = 0 #@param {type:'number'}\n",
        "minimum_entropy_loss = 0.0001 #@param {type:'number'}\n",
        "total_variation_loss = 0.1 #@param {type:'number'}\n",
        "iterations = 100 #@param {type:'integer'}\n",
        "terminal_iterations = 100 #@param {type:'integer'}\n",
        "show_every = 1 #@param {type:'integer'}\n",
        "save_every = 1 #@param {type:'integer'}\n",
        "fps = 1 #@param {type:'number'}\n",
        "freeze_secs = 0 #@param {type:'number'}\n",
        "seed =  0#@param {type:'number'}\n",
        "if seed == 0:\n",
        "  seed = None\n",
        "\n",
        "softmax_temp = 1\n",
        "emb_factor = 0.067 #calculated empirically \n",
        "loss_factor = 100\n",
        "sigma0 = 0.5 #http://cma.gforge.inria.fr/cmaes_sourcecode_page.html#practical\n",
        "cma_adapt = True\n",
        "cma_diag = 'sigmoid' in gen_model\n",
        "cma_active = True\n",
        "cma_elitist = False\n",
        "noise_size = 128\n",
        "class_size = 128 if initial_class.lower()=='random embeddings' else 1000\n",
        "channels = 3 if color else 1\n",
        "\n",
        "gen_model = gen_model + '-' + size\n",
        "if gen_model != last_gen_model and 'biggan' in gen_model:\n",
        "  biggan_model = BigGAN.from_pretrained(gen_model).cuda().eval()\n",
        "  last_gen_model = gen_model\n",
        "if clip_model != last_clip_model:\n",
        "  perceptor, preprocess = clip.load(clip_model)\n",
        "  last_clip_model = clip_model\n",
        "clip_res = perceptor.visual.input_resolution\n",
        "sideX = sideY = int(size)\n",
        "if sideX<=clip_res and sideY<=clip_res:\n",
        "  augmentations = 1\n",
        "if 'CMA' not in optimizer:\n",
        "  pop_size = 1\n",
        "if 'biggan' not in gen_model:\n",
        "  optimize_class = False\n",
        "requires_grad = ('SGD' in optimizer or 'Adam' in optimizer) and ('terminal' not in optimizer or terminal_iterations>0)\n",
        "total_iterations = iterations + terminal_iterations*('terminal' in optimizer)\n",
        "\n",
        "def my_forward(self, z, class_label, truncation):\n",
        "  assert 0 < truncation <= 1\n",
        "\n",
        "  if initial_class.lower()=='random embeddings':\n",
        "    embed = class_label\n",
        "  else:\n",
        "    embed = self.embeddings(class_label)\n",
        "    \n",
        "  cond_vector = torch.cat((z, embed), dim=1)\n",
        "\n",
        "  z = self.generator(cond_vector, truncation)\n",
        "  return z\n",
        "BigGAN.forward = my_forward\n",
        "\n",
        "!rm -rf /content/output\n",
        "!mkdir -p /content/output\n",
        "\n",
        "import numpy as np\n",
        "state = None if not seed else np.random.RandomState(seed)\n",
        "np.random.seed(seed)\n",
        "import torch\n",
        "import torchvision\n",
        "import sys\n",
        "torch.manual_seed(np.random.randint(sys.maxsize))\n",
        "import imageio\n",
        "from IPython.display import HTML, Image, clear_output\n",
        "from scipy.stats import truncnorm, dirichlet\n",
        "from pytorch_pretrained_biggan import BigGAN, convert_to_images, one_hot_from_names, utils\n",
        "from torch import nn\n",
        "from nltk.corpus import wordnet as wn\n",
        "from base64 import b64encode\n",
        "from time import time\n",
        "import cma\n",
        "from cma.sigma_adaptation import CMAAdaptSigmaCSA, CMAAdaptSigmaTPA\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", cma.evolution_strategy.InjectionWarning)\n",
        "\n",
        "def replace_to_inplace_relu(model): #saves memory; from https://github.com/minyoungg/pix2latent/blob/master/pix2latent/model/biggan.py\n",
        "    for child_name, child in model.named_children():\n",
        "        if isinstance(child, nn.ReLU):\n",
        "            setattr(model, child_name, nn.ReLU(inplace=False))\n",
        "        else:\n",
        "            replace_to_inplace_relu(child)\n",
        "    return\n",
        "replace_to_inplace_relu(biggan_model)\n",
        "replace_to_inplace_relu(perceptor)\n",
        "\n",
        "ind2name = {index: wn.of2ss('%08dn'%offset).lemma_names()[0] for offset, index in utils.IMAGENET.items()}\n",
        "\n",
        "def save(out,name=None):\n",
        "  with torch.no_grad():\n",
        "    out = out.cpu().numpy()\n",
        "  img = convert_to_images(out)[0]\n",
        "  if name:\n",
        "    imageio.imwrite(name, np.asarray(img))\n",
        "  return img\n",
        "\n",
        "hist = []\n",
        "def checkin(i, best_ind, total_losses, losses, regs, out, noise=None, emb=None, probs=None):\n",
        "  global sample_num, hist\n",
        "  name = None\n",
        "  if save_every and i%save_every==0:\n",
        "    name = '/content/output/frame_%05d.jpg'%sample_num\n",
        "  pil_image = save(out, name)\n",
        "  vals0 = [sample_num, i, total_losses[best_ind], losses[best_ind], regs[best_ind], np.mean(total_losses), np.mean(losses), np.mean(regs), np.std(total_losses), np.std(losses), np.std(regs)]\n",
        "  stats = 'sample=%d iter=%d best: total=%.2f cos=%.2f reg=%.3f avg: total=%.2f cos=%.2f reg=%.3f std: total=%.2f cos=%.2f reg=%.3f'%tuple(vals0)\n",
        "  vals1 = []\n",
        "  if noise is not None:\n",
        "    vals1 = [np.mean(noise), np.std(noise)]\n",
        "    stats += ' noise: avg=%.2f std=%.3f'%tuple(vals1)\n",
        "  vals2 = []\n",
        "  if emb is not None:\n",
        "    vals2 = [emb.mean(),emb.std()]\n",
        "    stats += ' emb: avg=%.2f std=%.3f'%tuple(vals2)\n",
        "  elif probs:\n",
        "    best = probs[best_ind]\n",
        "    inds = np.argsort(best)[::-1]\n",
        "    probs = np.array(probs)\n",
        "    vals2 = [ind2name[inds[0]], best[inds[0]], ind2name[inds[1]], best[inds[1]], ind2name[inds[2]], best[inds[2]], np.sum(probs >= 0.5)/pop_size,np.sum(probs >= 0.3)/pop_size,np.sum(probs >= 0.1)/pop_size]\n",
        "    stats += ' 1st=%s(%.2f) 2nd=%s(%.2f) 3rd=%s(%.2f) components: >=0.5:%.0f, >=0.3:%.0f, >=0.1:%.0f'%tuple(vals2)\n",
        "  hist.append(vals0+vals1+vals2)\n",
        "  if show_every and i%show_every==0:\n",
        "    clear_output()\n",
        "    display(pil_image)  \n",
        "  print(stats)\n",
        "  sample_num += 1\n",
        "\n",
        "eps = 1e-8\n",
        "class_vector = None\n",
        "if 'sigmoid' in gen_model:\n",
        "  noise_size = channels*sideY*sideX\n",
        "  noise_vector = np.random.rand(pop_size, noise_size).astype(np.float32)\n",
        "  noise_vector = np.log((noise_vector+eps)/(1-noise_vector+eps))\n",
        "else:\n",
        "  noise_vector = truncnorm.rvs(-2*truncation, 2*truncation, size=(pop_size, noise_size), random_state=state).astype(np.float32) #see https://github.com/tensorflow/hub/issues/214\n",
        "\n",
        "  if initial_class.lower() == 'random class':\n",
        "    class_vector = np.ones(shape=(pop_size, class_size), dtype=np.float32)*class_smoothing/999\n",
        "    class_vector[0,np.random.randint(class_size)] = 1-class_smoothing\n",
        "  elif initial_class.lower() == 'random dirichlet':\n",
        "    class_vector = dirichlet.rvs([pop_size/class_size] * class_size, size=1, random_state=state).astype(np.float32)\n",
        "  elif initial_class.lower() == 'random mix':\n",
        "    class_vector = np.random.rand(pop_size, class_size).astype(np.float32)\n",
        "  elif initial_class.lower() == 'random embeddings':\n",
        "    class_vector = np.random.randn(pop_size, class_size).astype(np.float32)\n",
        "  else:\n",
        "    if initial_class.lower() == 'from prompt':\n",
        "      initial_class = prompt\n",
        "    try:\n",
        "      class_vector = None\n",
        "      class_vector = one_hot_from_names(initial_class, batch_size=pop_size)\n",
        "      assert class_vector is not None\n",
        "      class_vector = class_vector*(1-class_smoothing*class_size/(class_size-1))+class_smoothing/(class_size-1)\n",
        "    except Exception as e:  \n",
        "      print('Error: could not find initial_class. Try something else.')\n",
        "      raise e\n",
        "\n",
        "  if initial_class.lower() != 'random embeddings':\n",
        "    class_vector = class_vector/np.sum(class_vector,axis=-1, keepdims=True)\n",
        "    class_vector = np.log(class_vector+eps)-np.mean(np.log(class_vector+eps),axis=-1, keepdims=True)\n",
        "  initial_class_vector = class_vector[0]\n",
        "  if initial_class.lower() in ('random mix','random embeddings'):\n",
        "    initial_class_vector = initial_class_vector*0\n",
        "  class_vector = torch.tensor(class_vector, requires_grad=requires_grad, device='cuda')\n",
        "  smoothed_ent = -torch.tensor(class_smoothing*np.log(class_smoothing/999+eps)+(1-class_smoothing)*np.log(1-class_smoothing+eps), dtype=torch.float32).cuda()\n",
        "noise_vector = torch.tensor(noise_vector, requires_grad=requires_grad, device='cuda')\n",
        "\n",
        "if requires_grad:\n",
        "  params = [noise_vector]\n",
        "  if optimize_class:\n",
        "    params = params + [class_vector]\n",
        "  if 'SGD' in optimizer:\n",
        "    optim = torch.optim.SGD(params, lr=learning_rate, momentum=0.9)  \n",
        "  else:\n",
        "    optim = torch.optim.Adam(params, lr=learning_rate)\n",
        "\n",
        "tx = clip.tokenize(prompt)\n",
        "with torch.no_grad():\n",
        "  target_clip = perceptor.encode_text(tx.cuda())\n",
        "\n",
        "def get_output(noise_vector, class_vector):\n",
        "  save_class_vector_norm = None\n",
        "  if 'sigmoid' in gen_model:\n",
        "    out = noise_vector.sigmoid().reshape(1, channels, sideY, sideX)*2-1\n",
        "  else:\n",
        "    if stochastic_truncation: #https://arxiv.org/abs/1702.04782\n",
        "      with torch.no_grad():\n",
        "        trunc_indices = noise_vector.abs() > 2*truncation\n",
        "        size = torch.count_nonzero(trunc_indices).cpu().numpy()\n",
        "        trunc = truncnorm.rvs(-2*truncation, 2*truncation, size=(1,size)).astype(np.float32)\n",
        "        noise_vector.data[trunc_indices] = torch.tensor(trunc, requires_grad=requires_grad, device='cuda')\n",
        "    else:\n",
        "      noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
        "    if initial_class.lower() == 'random embeddings':\n",
        "      class_vector_norm = class_vector*emb_factor\n",
        "    else:\n",
        "      class_vector_norm = torch.softmax(class_vector/softmax_temp,dim=-1)\n",
        "    out = biggan_model(noise_vector, class_vector_norm, truncation)\n",
        "    if channels==1:\n",
        "      out = out.mean(dim=1, keepdim=True)\n",
        "    if initial_class.lower() != 'random embeddings':\n",
        "      save_class_vector_norm = class_vector_norm\n",
        "  if channels==1:\n",
        "    out = out.repeat(1,3,1,1)\n",
        "  return out, save_class_vector_norm\n",
        "\n",
        "def normality_loss(vec): #https://arxiv.org/abs/1903.00925\n",
        "    mu2 = vec.mean().square()\n",
        "    sigma2 = vec.var()\n",
        "    return mu2+sigma2-torch.log(sigma2)-1\n",
        "\n",
        "global_best_loss = np.inf\n",
        "global_best_iteration = 0\n",
        "global_best_noise_vector = None\n",
        "global_best_class_vector = None\n",
        "def ascend_txt(i, grad_step=False, show_save=False):\n",
        "  global global_best_loss, global_best_iteration, global_best_noise_vector, global_best_class_vector\n",
        "  prev_class_vector_norms = []\n",
        "  regs = []\n",
        "  losses = []\n",
        "  total_losses = []\n",
        "  best_loss = np.inf\n",
        "  global_reg = torch.tensor(0, device='cuda', dtype=torch.float32, requires_grad=grad_step)\n",
        "  if 'biggan' in gen_model:\n",
        "    if optimize_class and embed_normality_loss and initial_class.lower() == 'random embeddings':\n",
        "      global_reg = global_reg+embed_normality_loss*normality_loss(class_vector)\n",
        "    if noise_normality_loss:\n",
        "      global_reg = global_reg+noise_normality_loss*normality_loss(noise_vector)\n",
        "    global_reg = loss_factor*global_reg  \n",
        "    if grad_step:\n",
        "      global_reg.backward()\n",
        "  for j in range(pop_size):\n",
        "    p_s = []\n",
        "    out, class_vector_norm = get_output(noise_vector[j:j+1], None if class_vector is None else class_vector[j:j+1])\n",
        "    if class_vector_norm is not None:\n",
        "      with torch.no_grad():\n",
        "        prev_class_vector_norms.append(class_vector_norm.cpu().numpy()[0])\n",
        "    \n",
        "    for aug in range(augmentations):\n",
        "      if sideX<=clip_res and sideY<=clip_res or augmentations==1:\n",
        "        apper = out  \n",
        "      else:\n",
        "        size = torch.randint(int(.7*sideX), int(.98*sideX), ())\n",
        "        offsetx = torch.randint(0, sideX - size, ())\n",
        "        offsety = torch.randint(0, sideX - size, ())\n",
        "        apper = out[:, :, offsetx:offsetx + size, offsety:offsety + size]\n",
        "      apper = (apper+1)/2\n",
        "      apper = nn.functional.interpolate(apper, clip_res, mode='bilinear')\n",
        "      #apper = apper.clamp(0,1)\n",
        "      p_s.append(apper)\n",
        "    into = nom(torch.cat(p_s, 0))\n",
        "    predict_clip = perceptor.encode_image(into)\n",
        "    loss = loss_factor*(1-torch.cosine_similarity(predict_clip, target_clip).mean())\n",
        "    total_loss = loss\n",
        "    regs.append(global_reg.item())\n",
        "    if 'sigmoid' in gen_model and total_variation_loss or 'biggan' in gen_model and optimize_class and minimum_entropy_loss and initial_class.lower() != 'random embeddings':\n",
        "      if 'sigmoid' in gen_model and total_variation_loss:\n",
        "        reg = total_variation_loss*((out[:, :, :-1, :] - out[:, :, 1:, :]).abs().mean() + (out[:, :, :, :-1] - out[:, :, :, 1:]).abs().mean())\n",
        "      elif 'biggan' in gen_model and optimize_class and minimum_entropy_loss and initial_class.lower() != 'random embeddings':\n",
        "        reg = minimum_entropy_loss*((-class_vector_norm*torch.log(class_vector_norm+eps)).sum()-smoothed_ent).abs()\n",
        "      reg = loss_factor*reg\n",
        "      total_loss = total_loss + reg\n",
        "      with torch.no_grad():\n",
        "        regs[-1] += reg.item()\n",
        "    with torch.no_grad():\n",
        "      losses.append(loss.item())\n",
        "      total_losses.append(total_loss.item()+global_reg.item())\n",
        "    if total_losses[-1]<best_loss:\n",
        "      best_loss = total_losses[-1]\n",
        "      best_ind = j\n",
        "      best_out = out\n",
        "      if best_loss < global_best_loss:\n",
        "        global_best_loss = best_loss\n",
        "        global_best_iteration = i\n",
        "        with torch.no_grad():\n",
        "          global_best_noise_vector = noise_vector[best_ind]\n",
        "          if class_vector is not None:\n",
        "            global_best_class_vector = class_vector[best_ind]\n",
        "\n",
        "    if grad_step:    \n",
        "      total_loss.backward()\n",
        "\n",
        "  if grad_step:\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "  if show_save and (save_every and i % save_every == 0 or show_every and i % show_every == 0):\n",
        "    noise = None\n",
        "    emb = None\n",
        "    if 'biggan' in gen_model:\n",
        "      with torch.no_grad():\n",
        "        noise = noise_vector.cpu().numpy()\n",
        "        if initial_class.lower() == 'random embeddings':\n",
        "          emb = class_vector.cpu().numpy()\n",
        "    checkin(i, best_ind, total_losses, losses, regs, best_out, noise, emb, prev_class_vector_norms)  \n",
        "  return total_losses, best_ind\n",
        "\n",
        "nom = torchvision.transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "if 'CMA' in optimizer:\n",
        "  initial_vector = np.zeros(noise_size)\n",
        "  bounds = None\n",
        "  #if 'biggan' in gen_model and not stochastic_truncation:\n",
        "  #  bounds = [-2*truncation*np.ones(noise_size),2*truncation*np.ones(noise_size)]\n",
        "  if optimize_class:\n",
        "    initial_vector = np.hstack([initial_vector, initial_class_vector])\n",
        "    #if not stochastic_truncation:\n",
        "    #  bounds[0] = list(bounds[0]) + [None]*class_size\n",
        "    #  bounds[1] = list(bounds[1]) + [None]*class_size\n",
        "  cma_opts = {'popsize': pop_size, 'seed': np.nan, 'AdaptSigma': cma_adapt, 'CMA_diagonal': cma_diag, 'CMA_active': cma_active, 'CMA_elitist':cma_elitist, 'bounds':bounds}\n",
        "  cmaes = cma.CMAEvolutionStrategy(initial_vector, sigma0, inopts=cma_opts)\n",
        "\n",
        "sample_num = 0\n",
        "machine = !nvidia-smi -L\n",
        "start = time()\n",
        "for i in range(total_iterations):    \n",
        "  if 'CMA' in optimizer and i<iterations:\n",
        "    with torch.no_grad():\n",
        "      cma_results = torch.tensor(cmaes.ask(), dtype=torch.float32).cuda()\n",
        "      if optimize_class:\n",
        "        noise_vector.data, class_vector.data = torch.split_with_sizes(cma_results, (noise_size, class_size), dim=-1)\n",
        "        class_vector.data = class_vector.data\n",
        "      else:\n",
        "        noise_vector.data = cma_results      \n",
        "  if requires_grad and ('terminal' not in optimizer or i>=iterations):\n",
        "    losses, best_ind = ascend_txt(i, grad_step=True, show_save='CMA' not in optimizer or i>=iterations)\n",
        "    assert noise_vector.requires_grad and noise_vector.is_leaf and (not optimize_class or class_vector.requires_grad and class_vector.is_leaf), (noise_vector.requires_grad, noise_vector.is_leaf, class_vector.requires_grad, class_vector.is_leaf)\n",
        "  if 'CMA' in optimizer and i<iterations:\n",
        "    with torch.no_grad():\n",
        "      losses, best_ind = ascend_txt(i, show_save=True)\n",
        "      if i<iterations-1:\n",
        "        if optimize_class:\n",
        "          vectors = torch.cat([noise_vector,class_vector], dim=1)\n",
        "        else:\n",
        "          vectors = noise_vector\n",
        "        cmaes.tell(vectors.cpu().numpy(), losses)\n",
        "      elif 'terminal' in optimizer and terminal_iterations:\n",
        "        pop_size = 1\n",
        "        noise_vector[0] = global_best_noise_vector\n",
        "        if class_vector is not None:\n",
        "          class_vector[0] = global_best_class_vector\n",
        "  if save_every and i % save_every == 0 or show_every and i % show_every == 0:\n",
        "    print('took: %d secs (%.2f sec/iter) on %s. CUDA memory: %.1f GB'%(time()-start,(time()-start)/(i+1), machine[0], torch.cuda.max_memory_allocated()/1024**3))\n",
        "\n",
        "out, _ = get_output(global_best_noise_vector.unsqueeze(0), None if global_best_class_vector is None else global_best_class_vector.unsqueeze(0))\n",
        "name = '/content/%s.jpg'%prompt\n",
        "pil_image = save(out,name)  \n",
        "display(pil_image)  \n",
        "print('best_loss=%.2f best_iter=%d'%(global_best_loss,global_best_iteration))\n",
        "\n",
        "from google.colab import files, output\n",
        "files.download('/content/%s.jpg'%prompt)\n",
        "\n",
        "out = '\"/content/%s.mp4\"'%prompt\n",
        "with open('/content/list.txt','w') as f:\n",
        "  for i in range(sample_num):\n",
        "    f.write('file /content/output/frame_%05d.jpg\\n'%i)\n",
        "  for j in range(int(freeze_secs*fps)):\n",
        "    f.write('file /content/output/frame_%05d.jpg\\n'%i)\n",
        "!ffmpeg -r $fps -f concat -safe 0 -i /content/list.txt -c:v libx264 -pix_fmt yuv420p -profile:v baseline -movflags +faststart -r $fps $out -y\n",
        "with open('/content/%s.mp4'%prompt, 'rb') as f:\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(f.read()).decode()\n",
        "display(HTML(\"\"\"\n",
        "  <video controls autoplay loop>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\"\"\" % data_url))\n",
        "\n",
        "from google.colab import files, output\n",
        "output.eval_js('new Audio(\"https://freesound.org/data/previews/80/80921_1022651-lq.ogg\").play()')\n",
        "files.download('/content/%s.mp4'%prompt)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}